{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1645634285332,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true
      },
      "source": [
        "# PROJECTS"
      ]
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "hidden": true
      },
      "source": [
        "# create a client\nclient\u003ddataiku.api_client()\nprojects\u003dclient.list_projects()\n\n# print all projects\nfor p in projects:\n    print (p[\u0027projectKey\u0027])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "BOOK_RECOMENDER_SYSTEM\nBOOK_RECOMMENDER_SYSTEM_NEW\nCCFRAUDADVANCEDCORESTART\nCCFRAUDDEPLOYERSTARTER\nCUSTOMER_LIFETIME_VALUE_UPDATED_VERSION\nDKU_CHURN\nDKU_CUSTOMER_LIFETIME_VALUE\nDKU_EXAM_ADV_DESIGNER\nDKU_EXAM_DEVELOPER\nDKU_EXAM_ML_PRACTITIONER\nDKU_HAIKU_STARTER\nDKU_HAIKU_STARTER_1\nDKU_TUTORIAL_AUTOMATION\nDKU_TUTORIAL_BASICS_101\nDKU_TUTORIAL_BASICS_101_1\nDKU_TUTORIAL_BASICS_101_2\nDKU_TUTORIAL_DATAIKU_APPS\nDKU_TUTORIAL_DATAIKU_APPS_0GdGiLRa\nDKU_TUTORIAL_DEPLOY\nDKU_TUTORIAL_IMAGE_CLASSIFICATION_THE_VISUAL_WAY\nDKU_TUTORIAL_INTERACTIVE_STATISTICS\nDKU_TUTORIAL_MACHINE_LEARNING_BASICS\nDKU_TUTORIAL_MACHINE_LEARNING_BASICS_1\nDKU_TUTORIAL_MACHINE_LEARNING_BASICS_2\nDKU_TUTORIAL_NLP_VISUAL\nDKU_TUTORIAL_NLP_VISUAL_1\nDKU_TUTORIAL_PARTITIONED_MODELS\nDKU_TUTORIAL_RTIMESERIES\nDKU_TUTORIAL_SQL\nDKU_TUTORIAL_TIME_SERIES_PREPARATION\nDKU_TUT_APIS\nDKU_TUT_CCFRAUD\nDKU_TUT_CCFRAUD_1\nDKU_TUT_CCFRAUD_2\nDKU_TUT_CCFRAUD_3\nDKU_TUT_CODE_NOTEBOOKS\nDKU_TUT_CUSTOMPREPROCESSING\nDKU_TUT_FLOWVIEWS\nDKU_TUT_FORECAST\nDKU_TUT_FUZZY_JOIN\nDKU_TUT_GEOJOIN\nDKU_TUT_PARTITION_COLBASED\nDKU_TUT_PARTITION_FILEBASED\nDKU_TUT_PARTITION_SCENARIO\nDKU_TUT_PLUGINDEV\nDKU_TUT_SHARECODE_A\nDKU_TUT_SHARECODE_B\nDKU_TUT_VARCOD\nDKU_TUT_VARCOD_1Bfc1hmv\nDKU_TUT_VISUALIZATION\nDKU_TUT_VIZ102_FORMULA\nDKU_TUT_VIZ102_WINDOW\nDOC_CLASS\nENERGYCONSUMPTIONPREDICTION\nEXCELIMPORT\nHAIKU\nHANDS_ON_FIRST_CERTIF\nHOUSE_PRICING\nINSTANCE_FINANCE\nINSURANCEFRAUDDETECTION\nINTERNATIONAL_FLIGHT_REPORTING\nNEWCCDISCOVERYSETUP\nPREDICTIVEMAINTENANCE\nPROCESSORDERS\nSEPHPRODUCTRATING\nSOL_STOCK_ALERT\nSQL_TEST\nSTARTER\nUN_PROJECT\nWOMENINDEX\nWOMEN_EQUALITY_INDEX_DUPLICATED_BRANCH\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {
        "hidden": true
      },
      "source": [
        "# print current project\ndataiku.default_project_key()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "\u0027ENERGYCONSUMPTIONPREDICTION\u0027"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATASETS"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\nmydataset \u003d dataiku.Dataset(\"mydataset\")\nmydataset_df \u003d mydataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client\u003ddataiku.api_client()\nif dataiku.default_project_key()\u003d\u003d\u0027ENERGYCONSUMPTIONPREDICTION\u0027:\n    outcome\u003d\u0027SUCCESS\u0027\nelse: \n    outcome\u003d\u0027FAILED\u0027"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset\u003ddataiku.Dataset(\"full_data_enriched\")\nfull_data_df"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FOLDERS"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Recipe inputs\ninput_dataset_name \u003d dataiku.Dataset(\"input_dataset_name\")\ninput_dataset_name_df \u003d input_dataset_name.get_dataframe()\n\n# Recipe outputs\nfolder_name \u003d dataiku.Folder(\"folder_id\")\nfolder_name_path \u003d folder_name.get_path()\n\nimport time\ncurrent_day \u003d time.strftime(\"%Y-%m-%d\")\ninput_dataset_name_df.to_csv(path_or_buf\u003dfolder_name_path+\"export_\"+current_day+\".csv\", index\u003dFalse)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VARIABLES"
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project_handle \u003d dataiku.api_client().get_project(dataiku.default_project_key())\nvariables\u003dproject_handle.get_variables()\nvariables[\u0027standard\u0027][\u0027cities_list\u0027]\u003d\u0027my_list\u0027\nproject_handle.set_variables(variables)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PARTITIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### On peut spécifier une recette générale puis expliciter la partition que l\u0027on veut construire avec l\u0027engrenage! "
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# lister les partitions\ndataset.list_partitions()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name \u0027dataset\u0027 is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-2-c7c5a27eb38c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name \u0027dataset\u0027 is not defined"
          ]
        }
      ]
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n# Read recipe inputs\ninput_ \u003d dataiku.Dataset(\"input\")\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\n# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\ninput_df \u003d input_.get_dataframe()\n\n# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\npartitioned_code_input_df \u003d input_df # For this sample code, simply copy input to output\n\n# cette cellule ne marchera pas dans un notebook (mais ok dans une recette)\npartitioned_code_input_df[\"ma_partition\"] \u003d dataiku.dku_flow_variables[\"DKU_DST_DATE\"]\n\n# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n# Write recipe outputs\npartitioned_code_input \u003d dataiku.Dataset(\"partitioned_output\")\npartitioned_code_input.write_with_schema(partitioned_code_input_df)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Unable to fetch schema for ENERGYCONSUMPTIONPREDICTION.input: b\u0027dataset does not exist: ENERGYCONSUMPTIONPREDICTION.input\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-4-9a41b7d3d42d\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#input.read_partitions \u003d [\u00272013-09-19\u0027, \u00272013-09-26\u0027]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(self, columns, sampling, sampling_column, limit, ratio, infer_with_pandas, parse_dates, bool_as_str, float_precision, na_values, keep_default_na)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0minfer_with_pandas\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0minfer_with_pandas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 407\u001b[0;31m             bool_as_str\u003dbool_as_str) # see df_from_split_desc\n\u001b[0m\u001b[1;32m    408\u001b[0m         with self._stream(infer_with_pandas\u003dinfer_with_pandas,\n\u001b[1;32m    409\u001b[0m                           \u001b[0msampling\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36m_get_dataframe_schema\u001b[0;34m(self, columns, parse_dates, infer_with_pandas, bool_as_str)\u001b[0m\n\u001b[1;32m    524\u001b[0m                                                    columns, parse_dates, infer_with_pandas, bool_as_str)\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 526\u001b[0;31m             return Dataset.get_dataframe_schema_st(self.read_schema(),\n\u001b[0m\u001b[1;32m    527\u001b[0m                                                    columns, parse_dates, infer_with_pandas, bool_as_str)\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36mread_schema\u001b[0;34m(self, raise_if_empty)\u001b[0m\n\u001b[1;32m    336\u001b[0m             self.cols \u003d intercom.jek_or_backend_json_call(\"datasets/get-schema/\", data\u003d{\n\u001b[1;32m    337\u001b[0m                 \u001b[0;34m\"fullDatasetName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 338\u001b[0;31m             }, err_msg\u003d\u0027Unable to fetch schema for %s\u0027%(self.name)).get(\"columns\")\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_if_empty\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36mjek_or_backend_json_call\u001b[0;34m(path, data, err_msg, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjek_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackend_get_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36mbackend_json_call\u001b[0;34m(path, data, err_msg, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackend_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_handle_json_resp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_api_post_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjek_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/carolineboudier/Desktop/dataiku-dss-10.0.0-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36m_handle_json_resp\u001b[0;34m(resp, err_msg)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0merr_data\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No details\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Unable to fetch schema for ENERGYCONSUMPTIONPREDICTION.input: b\u0027dataset does not exist: ENERGYCONSUMPTIONPREDICTION.input\u0027"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read only certain partitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u003ccode\u003einput_ds \u003d dataiku.Dataset(\"input\")\ninput_ds.read_partitions \u003d [\u00272013-09-19\u0027, \u00272013-09-26\u0027]\ndf_part \u003d input_ds.get_dataframe()\n\u003c/code\u003e"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}